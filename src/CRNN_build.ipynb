{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c30a4ea-ec3d-4858-be85-2d94922f6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed\n",
    "#!pip install tensorflow -q\n",
    "#!pip install opencv-python -q\n",
    "#!pip install tensorflow-addons -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfc69b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import json\n",
    "\n",
    "from modules.pym_dataframe import get_clean_dataframe\n",
    "from modules.pym_image_preprocessing import preprocess\n",
    "from modules.pym_crnn import ctc_loss, build_crnn\n",
    "from modules.pym_encoding import encode_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c29f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train & test data\n",
    "batch_size = 64\n",
    "imgSize = (32, 128) \n",
    "\n",
    "df = get_clean_dataframe()\n",
    "X_train_path, X_test_path, y_train, y_test = train_test_split(df.path, df.transcription_word, train_size=0.9, random_state=1234)\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
    "dataset_train = dataset_train.shuffle(10000).map(\n",
    "    lambda x, y : [preprocess(x, imgSize, scale=0.8), y]).batch(batch_size, drop_remainder=True)\n",
    "X_t, y_t = next(iter(dataset_train))\n",
    "\n",
    "dataset = dataset_train.map(lambda X,y : [X, encode_labels(y)])\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test_path, y_test))\n",
    "dataset_test = dataset_test.map(\n",
    "    lambda x, y : [preprocess(x, imgSize, scale=1), y]).batch(batch_size, drop_remainder=True)\n",
    "dataset_test = dataset_test.map(lambda X,y : [X, encode_labels(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ybeil\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py:303: UserWarning: modules.pym_models is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n"
     ]
    }
   ],
   "source": [
    "# For the first run we call the code below to build the CRNN\n",
    "#model = build_crnn(input_shape = X_t.shape[1:])\n",
    "# For the next run we load the model from the previous epoc\n",
    "model = tf.keras.models.load_model('./models/cnn_rnn_20.h5', compile=False)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2b88f-61cd-435f-abbd-e30c520bdbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could have used some callback or for loops to run the training on 20 epoc\n",
    "# But : a train last 20 min and take 100% CPU => For 20 epoch, it's 6h where my personal computer is at 100% CPU and not avalaible to do something else\n",
    "# So instead, i ran each training one by one (during breaks and free time), saved the model and the scores after each epoch \n",
    "# and adapt the learning rate according to the loss evolution\n",
    "model.compile(loss=ctc_loss, optimizer=Adam(1e-5))\n",
    "history = model.fit(dataset, epochs=1, validation_data=dataset_test)\n",
    "model.save('./models/cnn_rnn_20.h5') # save the model \n",
    "json.dump(history.history, open(\"./models/cnn_rnn_20.json\", 'w')) # save the loss and val_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "feebc6265df4a8cc88de779aa66e88304a65101fa70f24c662270f9f747a24e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
